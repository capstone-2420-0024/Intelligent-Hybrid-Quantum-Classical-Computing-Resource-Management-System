{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e78541",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def inject_anomalies(df, anomaly_fraction=0.01, random_seed=None):\n",
    "    \"\"\"\n",
    "    Injects realistic anomalies into sensor data based on known correlations and statistical properties.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame containing the sensor data\n",
    "    - anomaly_fraction: Fraction of data points to make anomalous (default: 1%)\n",
    "    - random_seed: Optional random seed for reproducibility\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with injected anomalies\n",
    "    - Array indicating which points are anomalies (1=anomaly, 0=normal)\n",
    "    \"\"\"\n",
    "\n",
    "    if random_seed is not None:\n",
    "        np.random.seed(random_seed)\n",
    "\n",
    "    # Create a copy of the dataframe and anomaly indicator\n",
    "    df_anomalous = df.copy()\n",
    "    anomaly_indicator = np.zeros(len(df))\n",
    "\n",
    "    # Get number of anomalies to inject\n",
    "    n_anomalies = int(len(df) * anomaly_fraction)\n",
    "\n",
    "    if n_anomalies == 0:\n",
    "        return df_anomalous, anomaly_indicator\n",
    "\n",
    "    # Select random indices for anomalies\n",
    "    anomaly_indices = np.random.choice(len(df), size=n_anomalies, replace=False)\n",
    "    anomaly_indicator[anomaly_indices] = 1\n",
    "\n",
    "    # Define anomaly types and their probabilities\n",
    "    anomaly_types = ['shift', 'spike', 'noise', 'freeze', 'drift']\n",
    "    anomaly_probs = [0.3, 0.3, 0.2, 0.1, 0.1]  # Adjust based on your expected anomaly distribution\n",
    "\n",
    "    # Group channels by their correlation patterns\n",
    "    cooling_group = ['cooling_channel0', 'cooling_channel1', 'cooling_channel10', 'cooling_channel11']\n",
    "    temp_group = ['temperature_channel1', 'temperature_channel2', 'temperature_channel5']\n",
    "    maxigauge_correlated = ['maxigauge_channel3', 'maxigauge_channel5']\n",
    "    maxigauge_uncorrelated = ['maxigauge_channel1', 'maxigauge_channel2', 'maxigauge_channel4', 'maxigauge_channel6']\n",
    "\n",
    "    # For each anomaly point, inject anomalies preserving correlations\n",
    "    for idx in anomaly_indices:\n",
    "        anomaly_type = np.random.choice(anomaly_types, p=anomaly_probs)\n",
    "\n",
    "        if anomaly_type == 'shift':\n",
    "            # Persistent shift in values - affects correlated groups together\n",
    "            group = np.random.choice(['cooling', 'temp', 'maxigauge_corr', 'single'])\n",
    "\n",
    "            if group == 'cooling':\n",
    "                shift_amount = np.random.uniform(-5, 5)  # Based on std of cooling channels\n",
    "                for ch in cooling_group:\n",
    "                    if ch in df.columns:\n",
    "                        df_anomalous.at[idx, ch] += shift_amount\n",
    "\n",
    "            elif group == 'temp':\n",
    "                shift_amount = np.random.uniform(-10, 10)  # Based on std of temp channels\n",
    "                for ch in temp_group:\n",
    "                    if ch in df.columns:\n",
    "                        df_anomalous.at[idx, ch] += shift_amount\n",
    "\n",
    "            elif group == 'maxigauge_corr':\n",
    "                shift_amount = np.random.uniform(-100, 100)  # Based on std of maxigauge channels\n",
    "                for ch in maxigauge_correlated:\n",
    "                    if ch in df.columns:\n",
    "                        df_anomalous.at[idx, ch] += shift_amount\n",
    "            else:\n",
    "                # Single channel shift\n",
    "                ch = np.random.choice(df.columns)\n",
    "                if ch in cooling_group:\n",
    "                    df_anomalous.at[idx, ch] += np.random.uniform(-5, 5)\n",
    "                elif ch in temp_group:\n",
    "                    df_anomalous.at[idx, ch] += np.random.uniform(-10, 10)\n",
    "                elif ch in maxigauge_correlated:\n",
    "                    df_anomalous.at[idx, ch] += np.random.uniform(-100, 100)\n",
    "                else:\n",
    "                    df_anomalous.at[idx, ch] += np.random.uniform(-50, 50)\n",
    "\n",
    "        elif anomaly_type == 'spike':\n",
    "            # Temporary spike - can be positive or negative\n",
    "            group = np.random.choice(['cooling', 'temp', 'maxigauge', 'single'])\n",
    "\n",
    "            if group == 'cooling':\n",
    "                spike_factor = np.random.choice([-1, 1]) * np.random.uniform(2, 5)\n",
    "                for ch in cooling_group:\n",
    "                    if ch in df.columns:\n",
    "                        df_anomalous.at[idx, ch] *= spike_factor\n",
    "\n",
    "            elif group == 'temp':\n",
    "                spike_factor = np.random.choice([-1, 1]) * np.random.uniform(2, 5)\n",
    "                for ch in temp_group:\n",
    "                    if ch in df.columns:\n",
    "                        df_anomalous.at[idx, ch] *= spike_factor\n",
    "\n",
    "            elif group == 'maxigauge':\n",
    "                spike_factor = np.random.choice([-1, 1]) * np.random.uniform(2, 10)\n",
    "                for ch in maxigauge_correlated + maxigauge_uncorrelated:\n",
    "                    if ch in df.columns:\n",
    "                        df_anomalous.at[idx, ch] *= spike_factor\n",
    "            else:\n",
    "                # Single channel spike\n",
    "                ch = np.random.choice(df.columns)\n",
    "                if ch in cooling_group:\n",
    "                    df_anomalous.at[idx, ch] *= np.random.choice([-1, 1]) * np.random.uniform(2, 5)\n",
    "                elif ch in temp_group:\n",
    "                    df_anomalous.at[idx, ch] *= np.random.choice([-1, 1]) * np.random.uniform(2, 5)\n",
    "                else:\n",
    "                    df_anomalous.at[idx, ch] *= np.random.choice([-1, 1]) * np.random.uniform(2, 10)\n",
    "\n",
    "        elif anomaly_type == 'noise':\n",
    "            # Add random noise to all channels\n",
    "            for ch in df.columns:\n",
    "                if ch in cooling_group:\n",
    "                    df_anomalous.at[idx, ch] += np.random.normal(0, 2)  # About 40% of std\n",
    "                elif ch in temp_group:\n",
    "                    df_anomalous.at[idx, ch] += np.random.normal(0, 40)  # About 40% of std\n",
    "                elif ch in maxigauge_correlated:\n",
    "                    df_anomalous.at[idx, ch] += np.random.normal(0, 150)  # About 40% of std\n",
    "                else:\n",
    "                    df_anomalous.at[idx, ch] += np.random.normal(0, 20)  # Smaller noise for others\n",
    "\n",
    "        elif anomaly_type == 'freeze':\n",
    "            # Freeze values for a random channel or group\n",
    "            group = np.random.choice(['cooling', 'temp', 'maxigauge_corr', 'single'])\n",
    "\n",
    "            if group == 'cooling':\n",
    "                for ch in cooling_group:\n",
    "                    if ch in df.columns:\n",
    "                        df_anomalous.at[idx, ch] = df_anomalous.at[idx-1, ch] if idx > 0 else df_anomalous.at[idx, ch]\n",
    "\n",
    "            elif group == 'temp':\n",
    "                for ch in temp_group:\n",
    "                    if ch in df.columns:\n",
    "                        df_anomalous.at[idx, ch] = df_anomalous.at[idx-1, ch] if idx > 0 else df_anomalous.at[idx, ch]\n",
    "\n",
    "            elif group == 'maxigauge_corr':\n",
    "                for ch in maxigauge_correlated:\n",
    "                    if ch in df.columns:\n",
    "                        df_anomalous.at[idx, ch] = df_anomalous.at[idx-1, ch] if idx > 0 else df_anomalous.at[idx, ch]\n",
    "            else:\n",
    "                ch = np.random.choice(df.columns)\n",
    "                df_anomalous.at[idx, ch] = df_anomalous.at[idx-1, ch] if idx > 0 else df_anomalous.at[idx, ch]\n",
    "\n",
    "        elif anomaly_type == 'drift':\n",
    "            # Start a gradual drift\n",
    "            ch = np.random.choice(df.columns)\n",
    "            drift_direction = np.random.choice([-1, 1])\n",
    "\n",
    "            if ch in cooling_group:\n",
    "                drift_rate = np.random.uniform(0.1, 0.5)\n",
    "            elif ch in temp_group:\n",
    "                drift_rate = np.random.uniform(1, 5)\n",
    "            elif ch in maxigauge_correlated:\n",
    "                drift_rate = np.random.uniform(10, 50)\n",
    "            else:\n",
    "                drift_rate = np.random.uniform(1, 10)\n",
    "\n",
    "            # Apply drift to this and subsequent points (simplified - would be better in a real implementation)\n",
    "            df_anomalous.at[idx, ch] += drift_direction * drift_rate\n",
    "\n",
    "    return df_anomalous, anomaly_indicator\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
